{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-11T04:33:56.095784Z","iopub.execute_input":"2022-04-11T04:33:56.096040Z","iopub.status.idle":"2022-04-11T04:34:52.194502Z","shell.execute_reply.started":"2022-04-11T04:33:56.096010Z","shell.execute_reply":"2022-04-11T04:34:52.193828Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"IMPORTING LIBRARIES\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:34:52.195835Z","iopub.execute_input":"2022-04-11T04:34:52.196042Z","iopub.status.idle":"2022-04-11T04:34:52.200864Z","shell.execute_reply.started":"2022-04-11T04:34:52.196011Z","shell.execute_reply":"2022-04-11T04:34:52.200070Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Importing Deep Learning Libraries\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.optimizers import Adam,SGD,RMSprop","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:34:52.202432Z","iopub.execute_input":"2022-04-11T04:34:52.202669Z","iopub.status.idle":"2022-04-11T04:34:52.212233Z","shell.execute_reply.started":"2022-04-11T04:34:52.202635Z","shell.execute_reply":"2022-04-11T04:34:52.211535Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"picture_size = 48\nfolder_path = \"../input/face-expression-recognition-dataset/images/\"","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:34:52.214416Z","iopub.execute_input":"2022-04-11T04:34:52.214741Z","iopub.status.idle":"2022-04-11T04:34:52.220505Z","shell.execute_reply.started":"2022-04-11T04:34:52.214702Z","shell.execute_reply":"2022-04-11T04:34:52.219722Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"expression = 'happy'\n\nplt.figure(figsize= (12,12))\nfor i in range(1, 10, 1):\n    plt.subplot(3,3,i)\n    img = load_img(folder_path+\"train/\"+expression+\"/\"+\n                  os.listdir(folder_path + \"train/\" + expression)[i], target_size=(picture_size, picture_size))\n    plt.imshow(img)   \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:34:52.221861Z","iopub.execute_input":"2022-04-11T04:34:52.222150Z","iopub.status.idle":"2022-04-11T04:34:53.085658Z","shell.execute_reply.started":"2022-04-11T04:34:52.222113Z","shell.execute_reply":"2022-04-11T04:34:53.084992Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"expression = 'disgust'\n\nplt.figure(figsize= (12,12))\nfor i in range(1, 10, 1):\n    plt.subplot(3,3,i)\n    img = load_img(folder_path+\"train/\"+expression+\"/\"+\n                  os.listdir(folder_path + \"train/\" + expression)[i], target_size=(picture_size, picture_size))\n    plt.imshow(img)   \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:34:53.086840Z","iopub.execute_input":"2022-04-11T04:34:53.087578Z","iopub.status.idle":"2022-04-11T04:34:54.046656Z","shell.execute_reply.started":"2022-04-11T04:34:53.087538Z","shell.execute_reply":"2022-04-11T04:34:54.045996Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"batch_size=128\ndatagen_train=ImageDataGenerator()\ndatagen_val=ImageDataGenerator()\n\ntrain_set= datagen_train.flow_from_directory(folder_path+\"train\",\n                                            target_size=(picture_size,picture_size),\n                                            color_mode=\"grayscale\",\n                                             batch_size=batch_size,\n                                            class_mode=\"categorical\",\n                                            shuffle=True)\ntest_set=datagen_val.flow_from_directory(folder_path+\"validation\",\n                                       target_size=(picture_size,picture_size),\n                                       color_mode=\"grayscale\",\n                                       batch_size=batch_size,\n                                       class_mode=\"categorical\",\n                                       shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:34:54.047867Z","iopub.execute_input":"2022-04-11T04:34:54.048648Z","iopub.status.idle":"2022-04-11T04:35:00.007484Z","shell.execute_reply.started":"2022-04-11T04:34:54.048607Z","shell.execute_reply":"2022-04-11T04:35:00.005909Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"MODEL BUILDING","metadata":{}},{"cell_type":"code","source":"no_of_classes=7\n\nmodel=Sequential()\n\n#1st CNN layer\nmodel.add(Conv2D(64,(3,3),padding=\"same\",input_shape=(48,48,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\n#2nd CNN layer\nmodel.add(Conv2D(128,(5,5),padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#3rd CNN layer\nmodel.add(Conv2D(512,(3,3),padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n#4th CNN layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\n#Fully connected 1st layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(no_of_classes,activation=\"softmax\"))\n\nopt = Adam(learning_rate = 0.0001)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:35:00.008881Z","iopub.execute_input":"2022-04-11T04:35:00.009188Z","iopub.status.idle":"2022-04-11T04:35:02.617995Z","shell.execute_reply.started":"2022-04-11T04:35:00.009133Z","shell.execute_reply":"2022-04-11T04:35:02.613805Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fitting the Model with Training and Validation Data","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\ncheckpoint = ModelCheckpoint(\"./model.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\nreduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n\nepochs = 48\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer = Adam(learning_rate=0.001),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:35:02.619100Z","iopub.execute_input":"2022-04-11T04:35:02.619399Z","iopub.status.idle":"2022-04-11T04:35:02.633657Z","shell.execute_reply.started":"2022-04-11T04:35:02.619362Z","shell.execute_reply":"2022-04-11T04:35:02.632933Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(generator=train_set,\n                                steps_per_epoch=train_set.n//train_set.batch_size,\n                                epochs=epochs,\n                                validation_data = test_set,\n                                validation_steps = test_set.n//test_set.batch_size,\n                                callbacks=callbacks_list\n                                )","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:35:02.636429Z","iopub.execute_input":"2022-04-11T04:35:02.637014Z","iopub.status.idle":"2022-04-11T04:44:35.926640Z","shell.execute_reply.started":"2022-04-11T04:35:02.636906Z","shell.execute_reply":"2022-04-11T04:44:35.925843Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model.save_weights('face_emotion_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:44:35.927788Z","iopub.execute_input":"2022-04-11T04:44:35.928049Z","iopub.status.idle":"2022-04-11T04:44:35.994512Z","shell.execute_reply.started":"2022-04-11T04:44:35.928012Z","shell.execute_reply":"2022-04-11T04:44:35.993754Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Plotting Accuracy & Loss","metadata":{}},{"cell_type":"code","source":"plt.style.use('dark_background')\n\nplt.figure(figsize=(20,10))\nplt.subplot(1, 2, 1)\nplt.suptitle('Optimizer : Adam', fontsize=10)\nplt.ylabel('Loss', fontsize=16)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\n\nplt.subplot(1, 2, 2)\nplt.ylabel('Accuracy', fontsize=16)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T04:44:35.995694Z","iopub.execute_input":"2022-04-11T04:44:35.996054Z","iopub.status.idle":"2022-04-11T04:44:51.539471Z","shell.execute_reply.started":"2022-04-11T04:44:35.996014Z","shell.execute_reply":"2022-04-11T04:44:51.538788Z"},"trusted":true},"execution_count":17,"outputs":[]}]}